{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet --upgrade google-cloud-aiplatform google-cloud-storage"
      ],
      "metadata": {
        "id": "3PamipiRGk7w"
      },
      "id": "3PamipiRGk7w",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "import textwrap\n",
        "\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('â€¢', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ],
      "metadata": {
        "id": "2mzEu5u4AaOt"
      },
      "id": "2mzEu5u4AaOt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We load the dataset from Huggingface. We want the model to expand the short stories to make them more engaging for children, and produce a lesson at the end from the story."
      ],
      "metadata": {
        "id": "eiJNZl5R5yl1"
      },
      "id": "eiJNZl5R5yl1"
    },
    {
      "cell_type": "code",
      "id": "SP9385JdfajE9pbMqCJg1AYT",
      "metadata": {
        "tags": [],
        "id": "SP9385JdfajE9pbMqCJg1AYT",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730647606492,
          "user_tz": 300,
          "elapsed": 6323,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c0d8bb6-56e6-4358-9448-c258b7bba308"
      },
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"roneneldan/TinyStories\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "PROJECT_ID = \"jkwng-vertex-playground\"  # @param {type:\"string\"}\n",
        "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
        "BUCKET = \"jkwng-vertex-experiments\" # @param {type:\"string\"}\n",
        "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
        "    raise ValueError(\"Please set your PROJECT_ID\")\n",
        "\n",
        "\n",
        "import vertexai\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)"
      ],
      "metadata": {
        "id": "NSKEn4EZ_NY-"
      },
      "id": "NSKEn4EZ_NY-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We loaded 1000 random stories from the dataset."
      ],
      "metadata": {
        "id": "tp3pG8Ux57DN"
      },
      "id": "tp3pG8Ux57DN"
    },
    {
      "cell_type": "code",
      "source": [
        "shuffle_ds = ds['train'].shuffle(seed=42)\n",
        "sample_ds = shuffle_ds[:1000]"
      ],
      "metadata": {
        "id": "JvvBnduX9kCL"
      },
      "id": "JvvBnduX9kCL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is a sample story."
      ],
      "metadata": {
        "id": "ut2y2YBx5-du"
      },
      "id": "ut2y2YBx5-du"
    },
    {
      "cell_type": "code",
      "source": [
        "to_markdown(sample_ds['text'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "OUBqo2xf-3dT",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730647615752,
          "user_tz": 300,
          "elapsed": 190,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "757bcc4f-0a22-4f23-de33-f84889d1d166"
      },
      "id": "OUBqo2xf-3dT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> Tim and Mia like to play in the park. They see a big club on the ground. It is brown and long and heavy.\n> \n> \"Look, a club!\" Tim says. \"I can lift it!\"\n> \n> He tries to lift the club, but it is too tough. He falls down and drops the club.\n> \n> \"Ouch!\" he says. \"That hurt!\"\n> \n> Mia laughs. She is not mean, she just thinks it is funny.\n> \n> \"Let me try!\" she says. \"I can balance it!\"\n> \n> She picks up the club and puts it on her head. She walks slowly and carefully. She does not fall down.\n> \n> \"Wow!\" Tim says. \"You are good at balancing!\"\n> \n> \"Thank you!\" Mia says. \"It is fun!\"\n> \n> They take turns balancing the club on their heads, arms, and legs. They have a lot of fun with the club. They are happy and proud. They are good friends."
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test out the system instruction and set up the response schema. We want the model to output the story and the lesson as separate properties of the json so we can evaluate each of them individually later."
      ],
      "metadata": {
        "id": "qeZh5Hb36CAA"
      },
      "id": "qeZh5Hb36CAA"
    },
    {
      "cell_type": "code",
      "source": [
        "from vertexai.generative_models import GenerativeModel, GenerationConfig, Part, SafetySetting, FinishReason\n",
        "\n",
        "max_tokens = 8192\n",
        "temperature = 1\n",
        "top_p = 0.95\n",
        "\n",
        "response_schema = {\n",
        "  \"type\": \"object\",\n",
        "  \"properties\": {\n",
        "    \"story\": {\n",
        "      \"type\": \"string\",\n",
        "    },\n",
        "    \"lesson\": {\n",
        "      \"type\": \"string\",\n",
        "    },\n",
        "  },\n",
        "  \"required\": [\"story\", \"lesson\"],\n",
        "}\n",
        "generation_config = GenerationConfig(\n",
        "    temperature=temperature,\n",
        "    top_p=top_p,\n",
        "    max_output_tokens=max_tokens,\n",
        "    response_mime_type=\"application/json\",\n",
        "    response_schema=response_schema,\n",
        ")\n",
        "\n",
        "safety_settings = [\n",
        "    SafetySetting(\n",
        "        category=SafetySetting.HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n",
        "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
        "    ),\n",
        "    SafetySetting(\n",
        "        category=SafetySetting.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
        "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
        "    ),\n",
        "    SafetySetting(\n",
        "        category=SafetySetting.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n",
        "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
        "    ),\n",
        "    SafetySetting(\n",
        "        category=SafetySetting.HarmCategory.HARM_CATEGORY_HARASSMENT,\n",
        "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
        "    ),\n",
        "]\n",
        "\n",
        "system_prompt = \"\"\"\n",
        "You are a children\\'s story editor. You will be shown a simple children\\'s story that you will be asked to add\n",
        "details to the story to make it more engaging for children.\n",
        "\"\"\"\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "model = GenerativeModel(\n",
        "  \"gemini-1.5-pro-002\",\n",
        "  system_instruction=[system_prompt],\n",
        ")"
      ],
      "metadata": {
        "id": "76vZtCzW_n4n"
      },
      "id": "76vZtCzW_n4n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the instruction prompt template."
      ],
      "metadata": {
        "id": "9akZsduj6Naa"
      },
      "id": "9akZsduj6Naa"
    },
    {
      "cell_type": "code",
      "source": [
        "instr_prompt = \"\"\"\n",
        "Make the story more interesting. Do not add, remove, or change any details from the story.  Only add sentences to elaborate\n",
        "on what is already written. **Do not change any of the character\\'s dialog.** Include a lesson at the end that children can\n",
        "learn from the story.\n",
        "\n",
        "Story:\n",
        "\"\"\"\n",
        "\n",
        "prompt = instr_prompt + sample_ds['text'][0]\n",
        "print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfDrE2qJ_hK9",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730650923624,
          "user_tz": 300,
          "elapsed": 161,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "2829f6a2-e752-4bfe-ec7d-c2a85fc76707"
      },
      "id": "RfDrE2qJ_hK9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Make the story more interesting. Do not add, remove, or change any details from the story.  Only add sentences to elaborate\n",
            "on what is already written. **Do not change any of the character's dialog.** Include a lesson at the end that children can\n",
            "learn from the story.\n",
            "\n",
            "Story:\n",
            "Tim and Mia like to play in the park. They see a big club on the ground. It is brown and long and heavy.\n",
            "\n",
            "\"Look, a club!\" Tim says. \"I can lift it!\"\n",
            "\n",
            "He tries to lift the club, but it is too tough. He falls down and drops the club.\n",
            "\n",
            "\"Ouch!\" he says. \"That hurt!\"\n",
            "\n",
            "Mia laughs. She is not mean, she just thinks it is funny.\n",
            "\n",
            "\"Let me try!\" she says. \"I can balance it!\"\n",
            "\n",
            "She picks up the club and puts it on her head. She walks slowly and carefully. She does not fall down.\n",
            "\n",
            "\"Wow!\" Tim says. \"You are good at balancing!\"\n",
            "\n",
            "\"Thank you!\" Mia says. \"It is fun!\"\n",
            "\n",
            "They take turns balancing the club on their heads, arms, and legs. They have a lot of fun with the club. They are happy and proud. They are good friends.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\n",
        "    [prompt],\n",
        "    generation_config=generation_config,\n",
        "    safety_settings=safety_settings,\n",
        ")"
      ],
      "metadata": {
        "id": "X5vFwcbpEEYN"
      },
      "id": "X5vFwcbpEEYN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "resp_json = json.loads(response.text)\n",
        "print(json.dumps(resp_json, indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vh706pED7FV",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730650307980,
          "user_tz": 300,
          "elapsed": 202,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "680610a4-c429-41a3-9d02-69bb6a5e3e0e"
      },
      "id": "5vh706pED7FV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"story\": \"Tim and Mia, best friends since kindergarten, loved playing in their neighborhood park after school.  The park, filled with towering oak trees and colorful flowers, was their favorite place to explore and have adventures. One sunny afternoon, while playing hide-and-seek amongst the trees, they stumbled upon a big club lying on the ground. Its bark was a deep, rich brown, worn smooth by time and weather. The club was long, like a fallen branch, and surprisingly heavy. \\\"Look, a club!\\\" Tim exclaimed, his eyes wide with excitement. \\\"I can lift it!\\\"  Tim, always eager to show off his strength, bent down and grasped the heavy club. He pulled with all his might, his face turning red with effort, but the club wouldn't budge.  With a grunt, he lost his balance and tumbled to the ground, the club falling harmlessly beside him. \\\"Ouch!\\\" he cried, rubbing his bruised knee. \\\"That hurt!\\\" Mia giggled, not to be mean, but because Tim's fall was quite comical.  She couldn't help but let out a small laugh. \\\"Let me try!\\\" she declared confidently. \\\"I can balance it!\\\" Mia, known for her grace and balance, carefully picked up the club. With a focused look, she placed it gently on her head, feeling the weight evenly distributed. Slowly and steadily, she took one step, then another, her eyes fixed straight ahead. She walked with a delicate balance, not even wobbling. \\\"Wow!\\\" Tim exclaimed, his eyes filled with admiration. \\\"You are good at balancing!\\\" \\\"Thank you!\\\" Mia replied, beaming with pride. \\\"It is fun!\\\" Inspired by Mia's success, they spent the rest of the afternoon taking turns trying to balance the club on different parts of their bodies. They balanced it on their heads, their arms, and even their legs. The park echoed with their laughter as they stumbled and giggled, always helping each other up. They had so much fun together and marveled at their newfound balancing skills.  They ended the afternoon happy and proud of themselves, proving once again what good friends they were.\",\n",
            "  \"lesson\": \"Sometimes, things that seem difficult can be achieved with a different approach.  Like Mia, who balanced the club instead of trying to lift it, we can find different ways to solve problems by thinking creatively and never giving up.\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build out the batch request with the 1000 story samples from the dataset above."
      ],
      "metadata": {
        "id": "qM6Hyagf6b4Q"
      },
      "id": "qM6Hyagf6b4Q"
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO generate jsonl for all the stories using this prompt template\n",
        "# Import the Google Cloud client library and JSON library\n",
        "from google.cloud import storage\n",
        "import json\n",
        "\n",
        "bucket_name = 'jkwng-vertex-experiments'\n",
        "stories_prefix = 'stories'\n",
        "storage_client = storage.Client()\n",
        "bucket = storage_client.bucket(bucket_name)\n",
        "output_path = f\"{stories_prefix}/batch_input.jsonl\"\n",
        "output_blob = bucket.blob(output_path)"
      ],
      "metadata": {
        "id": "_GIrI8PbnY8K"
      },
      "id": "_GIrI8PbnY8K",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write out the dataset to json lines to prepare the batch prediction."
      ],
      "metadata": {
        "id": "kDPwtWIa6l9t"
      },
      "id": "kDPwtWIa6l9t"
    },
    {
      "cell_type": "code",
      "source": [
        "with output_blob.open(mode='w') as f:\n",
        "  lineCount = 0\n",
        "\n",
        "  for data in sample_ds['text']:\n",
        "    item = {}\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "Make the story more interesting. Do not add, remove, or change any details from the story.  Only add sentences to elaborate\n",
        "on what is already written. **Do not change any of the character\\'s dialog.** Include a lesson at the end that children can\n",
        "learn from the story.\n",
        "\n",
        "Story:\n",
        "{data}\n",
        "\"\"\"\n",
        "\n",
        "    # batch prediction is json representation of GenerateContentRequest\n",
        "\n",
        "    #print(vars(generation_config))\n",
        "    #print(data)\n",
        "    item['id'] = str(lineCount)\n",
        "    item['request'] = {\n",
        "        \"contents\": [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"parts\": [{\"text\": prompt}],\n",
        "            }\n",
        "        ],\n",
        "        \"system_instruction\": {\n",
        "          \"parts\": [{\"text\": system_prompt}],\n",
        "        },\n",
        "        \"generation_config\": generation_config.to_dict(),\n",
        "        \"safety_settings\": [s.to_dict() for s in safety_settings],\n",
        "    }\n",
        "\n",
        "    line = json.dumps(item).replace(\"\\\"type_\\\":\", \"\\\"type\\\":\") # annoying hack because type is a reserved key\n",
        "    lineCount += 1\n",
        "    f.write(f\"{line}\\n\")\n",
        "\n",
        "    if lineCount % 100 == 0:\n",
        "      print(f\"- Wrote {lineCount} lines to gs://{bucket_name}/{output_path} ...\")\n",
        "\n",
        "print(f\"Wrote {lineCount} total lines to gs://{bucket_name}/{output_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWXe6Ac4-nKv",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730647693123,
          "user_tz": 300,
          "elapsed": 598,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "6ee47c95-4954-4c75-bea8-e97a37dfffc0"
      },
      "id": "fWXe6Ac4-nKv",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Wrote 100 lines to gs://jkwng-vertex-experiments/stories/batch_input.jsonl ...\n",
            "- Wrote 200 lines to gs://jkwng-vertex-experiments/stories/batch_input.jsonl ...\n",
            "- Wrote 300 lines to gs://jkwng-vertex-experiments/stories/batch_input.jsonl ...\n",
            "- Wrote 400 lines to gs://jkwng-vertex-experiments/stories/batch_input.jsonl ...\n",
            "- Wrote 500 lines to gs://jkwng-vertex-experiments/stories/batch_input.jsonl ...\n",
            "- Wrote 600 lines to gs://jkwng-vertex-experiments/stories/batch_input.jsonl ...\n",
            "- Wrote 700 lines to gs://jkwng-vertex-experiments/stories/batch_input.jsonl ...\n",
            "- Wrote 800 lines to gs://jkwng-vertex-experiments/stories/batch_input.jsonl ...\n",
            "- Wrote 900 lines to gs://jkwng-vertex-experiments/stories/batch_input.jsonl ...\n",
            "- Wrote 1000 lines to gs://jkwng-vertex-experiments/stories/batch_input.jsonl ...\n",
            "Wrote 1000 total lines to gs://jkwng-vertex-experiments/stories/batch_input.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Batch Prediction"
      ],
      "metadata": {
        "id": "-O4J-2ypEj-l"
      },
      "id": "-O4J-2ypEj-l"
    },
    {
      "cell_type": "code",
      "source": [
        "from vertexai.batch_prediction import BatchPredictionJob\n",
        "from datetime import datetime\n",
        "import time\n",
        "\n",
        "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "output_uri_prefix=f\"gs://{bucket_name}/{stories_prefix}/batch_output_{TIMESTAMP}\"\n",
        "\n",
        "job = BatchPredictionJob.submit(\n",
        "    source_model=\"gemini-1.5-pro-002\",\n",
        "    input_dataset=f\"gs://{bucket_name}/{output_path}\",\n",
        "    output_uri_prefix=output_uri_prefix\n",
        ")\n",
        "\n",
        "print(f\"Writing to output: gs://{bucket_name}/{output_uri_prefix}\")\n",
        "print(f\"Job resource name: {job.resource_name}\")\n",
        "print(f\"Model resource name: {job.model_name}\")\n",
        "print(f\"Job state: {job.state.name}\")\n",
        "\n",
        "# Refresh the job until complete\n",
        "waitcount = 0\n",
        "while not job.has_ended:\n",
        "    time.sleep(5)\n",
        "    waitcount += 1\n",
        "    job.refresh()\n",
        "    if waitcount % 6 == 0:\n",
        "      print (f\"after {waitcount * 5} seconds, job state is {job.state.name} ...\")\n",
        "\n",
        "# Check if the job succeeds\n",
        "if job.has_succeeded:\n",
        "    print(f\"Job succeeded after {waitcount * 5} seconds. output: {job.output_location}\")\n",
        "else:\n",
        "    print(f\"Job failed: {job.error}\")"
      ],
      "metadata": {
        "id": "1lpBOXdX9rU2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730648168523,
          "user_tz": 300,
          "elapsed": 269571,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "36b874c5-5087-46c2-9def-5488863bd1e1"
      },
      "id": "1lpBOXdX9rU2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:vertexai.batch_prediction._batch_prediction:BatchPredictionJob created. Resource name: projects/205512073711/locations/us-central1/batchPredictionJobs/7486593743181578240\n",
            "INFO:vertexai.batch_prediction._batch_prediction:To use this BatchPredictionJob in another session:\n",
            "INFO:vertexai.batch_prediction._batch_prediction:job = batch_prediction.BatchPredictionJob('projects/205512073711/locations/us-central1/batchPredictionJobs/7486593743181578240')\n",
            "INFO:vertexai.batch_prediction._batch_prediction:View Batch Prediction Job:\n",
            "https://console.cloud.google.com/ai/platform/locations/us-central1/batch-predictions/7486593743181578240?project=205512073711\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing to output: gs://jkwng-vertex-experiments/gs://jkwng-vertex-experiments/stories/batch_output_20241103153139\n",
            "Job resource name: projects/205512073711/locations/us-central1/batchPredictionJobs/7486593743181578240\n",
            "Model resource name: publishers/google/models/gemini-1.5-pro-002\n",
            "Job state: JOB_STATE_PENDING\n",
            "after 30 seconds, job state is JOB_STATE_RUNNING ...\n",
            "after 60 seconds, job state is JOB_STATE_RUNNING ...\n",
            "after 90 seconds, job state is JOB_STATE_RUNNING ...\n",
            "after 120 seconds, job state is JOB_STATE_RUNNING ...\n",
            "after 150 seconds, job state is JOB_STATE_RUNNING ...\n",
            "after 180 seconds, job state is JOB_STATE_RUNNING ...\n",
            "after 210 seconds, job state is JOB_STATE_RUNNING ...\n",
            "after 240 seconds, job state is JOB_STATE_RUNNING ...\n",
            "Job succeeded after 265 seconds. output: gs://jkwng-vertex-experiments/stories/batch_output_20241103153139/prediction-model-2024-11-03T15:31:39.935840Z\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{job.output_location}\")\n",
        "job_output_location = job.output_location"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hb_vbrwOLc3T",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730648180073,
          "user_tz": 300,
          "elapsed": 166,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "95f53f94-872a-4f75-de5f-d264ccc58a31"
      },
      "id": "hb_vbrwOLc3T",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gs://jkwng-vertex-experiments/stories/batch_output_20241103153139/prediction-model-2024-11-03T15:31:39.935840Z\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess the prediction output into clear json objects that we can use for evaluation later.\n",
        "\n",
        "The json object schema looks like:\n",
        "```\n",
        "{\n",
        "  \"instruction\": <prompt instruction>,\n",
        "  \"original\": <original story>,\n",
        "  \"system_instruction\": <system prompt>,\n",
        "  \"story\": <AI generated story based on the original story>,\n",
        "  \"lesson\": <AI generated lesson drawn from the story>,\n",
        "}\n",
        "```"
      ],
      "metadata": {
        "id": "kv0GabPu6uJ9"
      },
      "id": "kv0GabPu6uJ9"
    },
    {
      "cell_type": "code",
      "source": [
        "# produce a dataset we can save for evaluation later\n",
        "#job_output_location = \"gs://jkwng-vertex-experiments/stories/dataset.jsonl/20241103131100/prediction-model-2024-11-03T13:11:00.461891Z\"\n",
        "\n",
        "from google.cloud.storage.blob import Blob\n",
        "\n",
        "output_blob = Blob.from_string(f\"{job_output_location}/predictions.jsonl\", storage_client)\n",
        "\n",
        "all_data = []\n",
        "\n",
        "with output_blob.open(mode='r') as f:\n",
        "  while line := f.readline():\n",
        "    data_obj = {}\n",
        "    output_data = json.loads(line)\n",
        "    data_id = output_data['id']\n",
        "\n",
        "    request = output_data['request']\n",
        "    req_system_instr = request['system_instruction']\n",
        "\n",
        "\n",
        "    #snip out the prompt, which should be in request[0].contents[0].parts[0].text\n",
        "    prompt_orig = request['contents'][0]['parts'][0]['text']\n",
        "    data_obj['instruction'] = instr_prompt\n",
        "    data_obj['original'] = prompt_orig.replace(instr_prompt, \"\")\n",
        "    data_obj['system_instruction'] = req_system_instr['parts'][0]['text']\n",
        "\n",
        "    response = output_data['response']\n",
        "    #print(response)\n",
        "\n",
        "    resp_obj = json.loads(response['candidates'][0]['content']['parts'][0]['text'])\n",
        "    data_obj['story'] = resp_obj['story']\n",
        "    data_obj['lesson'] = resp_obj['lesson']\n",
        "\n",
        "    #print(data_obj)\n",
        "    all_data.append(data_obj)\n",
        "\n",
        "\n",
        "# combine\n",
        "final_output_path = f\"{stories_prefix}/stories_dataset.jsonl\"\n",
        "final_output = bucket.blob(final_output_path)\n",
        "with final_output.open(mode='w') as f:\n",
        "  lineCount = 0\n",
        "\n",
        "  for data in all_data:\n",
        "    line = json.dumps(data)\n",
        "    lineCount += 1\n",
        "    f.write(f\"{line}\\n\")\n",
        "\n",
        "    if lineCount % 100 == 0:\n",
        "      print(f\"- Wrote {lineCount} lines to gs://{bucket_name}/{final_output_path} ...\")\n",
        "\n",
        "print(f\"Wrote {lineCount} total lines to gs://{bucket_name}/{final_output_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwyFQUOGLsvz",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730650974500,
          "user_tz": 300,
          "elapsed": 634,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "b9d2c906-fa11-4475-a52e-8ec5ff8f3b3b"
      },
      "id": "dwyFQUOGLsvz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Wrote 100 lines to gs://jkwng-vertex-experiments/stories/stories_dataset.jsonl ...\n",
            "- Wrote 200 lines to gs://jkwng-vertex-experiments/stories/stories_dataset.jsonl ...\n",
            "- Wrote 300 lines to gs://jkwng-vertex-experiments/stories/stories_dataset.jsonl ...\n",
            "- Wrote 400 lines to gs://jkwng-vertex-experiments/stories/stories_dataset.jsonl ...\n",
            "- Wrote 500 lines to gs://jkwng-vertex-experiments/stories/stories_dataset.jsonl ...\n",
            "- Wrote 600 lines to gs://jkwng-vertex-experiments/stories/stories_dataset.jsonl ...\n",
            "- Wrote 700 lines to gs://jkwng-vertex-experiments/stories/stories_dataset.jsonl ...\n",
            "- Wrote 800 lines to gs://jkwng-vertex-experiments/stories/stories_dataset.jsonl ...\n",
            "- Wrote 900 lines to gs://jkwng-vertex-experiments/stories/stories_dataset.jsonl ...\n",
            "- Wrote 1000 lines to gs://jkwng-vertex-experiments/stories/stories_dataset.jsonl ...\n",
            "Wrote 1000 total lines to gs://jkwng-vertex-experiments/stories/stories_dataset.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KoZv6kGzOvJi"
      },
      "id": "KoZv6kGzOvJi",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "stories_generation.ipynb"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}