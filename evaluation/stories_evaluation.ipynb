{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Vertex AI Evaluation\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "DzktWvbLzYOI"
      },
      "id": "DzktWvbLzYOI"
    },
    {
      "cell_type": "code",
      "id": "M5UJk5yohlGTTF3JMQNsEVq6",
      "metadata": {
        "tags": [],
        "id": "M5UJk5yohlGTTF3JMQNsEVq6",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730729730010,
          "user_tz": 300,
          "elapsed": 5290,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "source": [
        "%pip install --upgrade --user --quiet google-cloud-aiplatform[evaluation]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Variable definitions"
      ],
      "metadata": {
        "id": "IbVaCRDrglvk"
      },
      "id": "IbVaCRDrglvk"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "N-i6OtB9er8G",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730729737249,
          "user_tz": 300,
          "elapsed": 5254,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "PROJECT_ID = \"jkwng-vertex-playground\"  # @param {type:\"string\"}\n",
        "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
        "EXPERIMENT_NAME = \"stories-dataset-experiment\"  # @param {type:\"string\"}\n",
        "BUCKET = \"jkwng-vertex-experiments\" # @param {type:\"string\"}\n",
        "\n",
        "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
        "    raise ValueError(\"Please set your PROJECT_ID\")\n",
        "\n",
        "\n",
        "import vertexai\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)"
      ],
      "id": "N-i6OtB9er8G"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import statements"
      ],
      "metadata": {
        "id": "NsBHBKLZgimR"
      },
      "id": "NsBHBKLZgimR"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qP4ihOCkEBje",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730729740902,
          "user_tz": 300,
          "elapsed": 1125,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "# General\n",
        "import pandas as pd\n",
        "\n",
        "# Main\n",
        "from vertexai.evaluation import EvalTask, PointwiseMetric, PointwiseMetricPromptTemplate, MetricPromptTemplateExamples"
      ],
      "id": "qP4ihOCkEBje"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helper functions"
      ],
      "metadata": {
        "id": "y0VSqOCfgf8L"
      },
      "id": "y0VSqOCfgf8L"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gT_OJBHfCg4Q",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730729743500,
          "user_tz": 300,
          "elapsed": 146,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "from IPython.display import Markdown, display\n",
        "\n",
        "\n",
        "def display_eval_result(eval_result, metrics=None):\n",
        "    \"\"\"Display the evaluation results.\"\"\"\n",
        "    summary_metrics, metrics_table = (\n",
        "        eval_result.summary_metrics,\n",
        "        eval_result.metrics_table,\n",
        "    )\n",
        "\n",
        "    metrics_df = pd.DataFrame.from_dict(summary_metrics, orient=\"index\").T\n",
        "    if metrics:\n",
        "        metrics_df = metrics_df.filter(\n",
        "            [\n",
        "                metric\n",
        "                for metric in metrics_df.columns\n",
        "                if any(selected_metric in metric for selected_metric in metrics)\n",
        "            ]\n",
        "        )\n",
        "        metrics_table = metrics_table.filter(\n",
        "            [\n",
        "                metric\n",
        "                for metric in metrics_table.columns\n",
        "                if any(selected_metric in metric for selected_metric in metrics)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    # Display the summary metrics\n",
        "    display(Markdown(\"### Summary Metrics\"))\n",
        "    display(metrics_df)\n",
        "    # Display the metrics table\n",
        "    display(Markdown(\"### Row-based Metrics\"))\n",
        "    display(metrics_table)"
      ],
      "id": "gT_OJBHfCg4Q"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vertex AI includes the following built-in metrics for LLM evaluation. These metrics use pre-defined prompts and use the LLM-as-judge methodology to score model responses.\n",
        "\n",
        "We have printed out the metric prompt template for `fluency` for review.\n",
        "\n"
      ],
      "metadata": {
        "id": "7yZVz7GDgqTp"
      },
      "id": "7yZVz7GDgqTp"
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "# View all the available examples of model-based metrics\n",
        "pprint(MetricPromptTemplateExamples.list_example_metric_names())\n",
        "print(f\"\\nFluency:\\n {MetricPromptTemplateExamples.get_prompt_template('fluency')}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxrLpL9FRSRq",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730662444094,
          "user_tz": 300,
          "elapsed": 208,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "49a84958-bfc4-42a4-dc46-2fbdd6078138"
      },
      "id": "DxrLpL9FRSRq",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['coherence',\n",
            " 'fluency',\n",
            " 'safety',\n",
            " 'groundedness',\n",
            " 'instruction_following',\n",
            " 'verbosity',\n",
            " 'text_quality',\n",
            " 'summarization_quality',\n",
            " 'question_answering_quality',\n",
            " 'multi_turn_chat_quality',\n",
            " 'multi_turn_safety',\n",
            " 'pairwise_coherence',\n",
            " 'pairwise_fluency',\n",
            " 'pairwise_safety',\n",
            " 'pairwise_groundedness',\n",
            " 'pairwise_instruction_following',\n",
            " 'pairwise_verbosity',\n",
            " 'pairwise_text_quality',\n",
            " 'pairwise_summarization_quality',\n",
            " 'pairwise_question_answering_quality',\n",
            " 'pairwise_multi_turn_chat_quality',\n",
            " 'pairwise_multi_turn_safety']\n",
            "\n",
            "Fluency:\n",
            " \n",
            "# Instruction\n",
            "You are an expert evaluator. Your task is to evaluate the quality of the responses generated by AI models.\n",
            "We will provide you with the user input and an AI-generated response.\n",
            "You should first read the user input carefully for analyzing the task, and then evaluate the quality of the responses based on the criteria provided in the Evaluation section below.\n",
            "You will assign the response a rating following the Rating Rubric and Evaluation Steps. Give step by step explanations for your rating, and only choose ratings from the Rating Rubric.\n",
            "\n",
            "# Evaluation\n",
            "## Metric Definition\n",
            "You will be assessing fluency, which measures language mastery of the model's response based on the user prompt.\n",
            "\n",
            "## Criteria\n",
            "Fluency: The text is free of grammatical errors, employs varied sentence structures, and maintains a consistent tone and style, resulting in a smooth and natural flow that is easy to understand.\n",
            "\n",
            "## Rating Rubric\n",
            "5 (completely fluent): The response is free of grammatical errors, demonstrates nuanced word choice, and has a natural, seamless flow.\n",
            "4 (mostly fluent): The response has very few, if any, minor grammatical errors. Word choice is clear, and sentences generally flow well.\n",
            "3 (somewhat fluent): The response has grammatical errors present, which may cause some difficulty for the reader. Word choice is mostly appropriate, but some awkward phrasing or word repetition may exist.\n",
            "2 (somewhat inarticulate): The response has frequent grammatical errors that make the writing difficult to understand. Sentence structure is often awkward, and there's little sense of flow.\n",
            "1 (inarticulate): The response is riddled with grammatical issues, rendering it incomprehensible in parts. Word choices may be very limited or inaccurate.\n",
            "\n",
            "## Evaluation Steps\n",
            "STEP 1: Assess grammar correctness: Identify any specific errors in the response's sentence structure, verb usage, subject-verb agreement, punctuation, and capitalization.\n",
            "STEP 2: Assess word choice and flow: Examine the response's sentence structure and how the writing moves from one idea to the next. Are words accurate and well-suited to the context?\n",
            "STEP 3: Assess overall cohesion: Does the entire response read logically and smoothly, with appropriate transitions?\n",
            "\n",
            "\n",
            "# User Inputs and AI-generated Response\n",
            "## User Inputs\n",
            "### Prompt\n",
            "{prompt}\n",
            "\n",
            "## AI-generated Response\n",
            "{response}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below we have defined our own metrics based on our dataset:\n",
        "\n",
        "\n",
        "1.   Story quality: is the story understandable and relatable to children.\n",
        "2.   Faithfulness: is the generated story grounded in the original short story. We especially care if character dialogue was changed, or if new characters or major plot points were introduced.\n",
        "\n",
        "We will later map the `story` variable in our dataset to `response`, as these templates assume that the AI response to be evaluate is named `response`."
      ],
      "metadata": {
        "id": "pw80rLhKhUTj"
      },
      "id": "pw80rLhKhUTj"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "EGe_vlUvPVOM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730737881363,
          "user_tz": 300,
          "elapsed": 139,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "3f0b64b2-1144-49d9-cba8-6bef1d47f139"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:vertexai.evaluation.metrics.metric_prompt_template:The `input_variables` parameter is empty. Only the `response` column is used for computing this model-based metric.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Instruction\n",
            "You are an expert evaluator. Your task is to evaluate the quality of the responses generated by AI models. We will provide you with the user prompt and an AI-generated responses.\n",
            "You should first read the user input carefully for analyzing the task, and then evaluate the quality of the responses based on the Criteria provided in the Evaluation section below.\n",
            "You will assign the response a rating following the Rating Rubric and Evaluation Steps. Give step by step explanations for your rating, and only choose ratings from the Rating Rubric.\n",
            "\n",
            "\n",
            "# Evaluation\n",
            "## Criteria\n",
            "entertaining: The text is engaging, has enough descriptive text for children to immerse themselves in the story.\n",
            "relatable: The text contains a story that children can understand and relate to their daily lives.\n",
            "\n",
            "## Rating Rubric\n",
            "0: The story is incomprehensible to young children.\n",
            "1: The story contains details that children may be bored by, not understand, or not be able to relate to.\n",
            "2: The story contains things that children can relate to, but is not very entertaining.\n",
            "3: The story contains some parts that are entertaining or relatable to children.\n",
            "4: The story is mostly engaging to children with some minor exceptions.\n",
            "5: The story is very engaging to children.\n",
            "\n",
            "## Evaluation Steps\n",
            "Step 1: Assess the response in aspects of all criteria provided. Provide assessment according to each criterion.\n",
            "Step 2: Score based on the rating rubric. Give a brief rationale to explain your evaluation considering each individual criterion.\n",
            "\n",
            "\n",
            "# User Inputs and AI-generated Response\n",
            "## User Inputs\n",
            "\n",
            "\n",
            "\n",
            "## AI-generated Response\n",
            "{response}\n"
          ]
        }
      ],
      "source": [
        "# Your own definition of text_quality.\n",
        "story_quality_template = PointwiseMetricPromptTemplate(\n",
        "    criteria={\n",
        "        \"entertaining\": \"The text is engaging, has enough descriptive text for children to immerse themselves in the story.\",\n",
        "        \"relatable\": \"The text contains a story that children can understand and relate to their daily lives.\",\n",
        "    },\n",
        "    rating_rubric={\n",
        "        \"5\": \"The story is very engaging to children.\",\n",
        "        \"4\": \"The story is mostly engaging to children with some minor exceptions.\",\n",
        "        \"3\": \"The story contains some parts that are entertaining or relatable to children.\",\n",
        "        \"2\": \"The story contains things that children can relate to, but is not very entertaining.\",\n",
        "        \"1\": \"The story contains details that children may be bored by, not understand, or not be able to relate to.\",\n",
        "        \"0\": \"The story is incomprehensible to young children.\",\n",
        "    },\n",
        ")\n",
        "\n",
        "story_quality = PointwiseMetric(\n",
        "    metric=\"story_quality\",\n",
        "    metric_prompt_template=story_quality_template,\n",
        ")\n",
        "\n",
        "faithfulness_quality_template = PointwiseMetricPromptTemplate(\n",
        "    criteria={\n",
        "      \"faithfulness\": \"The text contains the same events from the original and does not introduce new characters, events or change any of the dialogue.\",\n",
        "    },\n",
        "    rating_rubric={\n",
        "        \"5\": \"The story is true to the original with no details added or removed, and no character dialogue changed.\",\n",
        "        \"4\": \"The story has minor details added, such as characters' inner thoughts or descriptions of settings, but the events remain the same and the character dialogue is exactly the same as the original.\",\n",
        "        \"3\": \"The story introduces minor changes to the plot, setting or character dialogue, but the plot of the story is the same as the original.\",\n",
        "        \"2\": \"The story introduces a minor new character or introduces or excludes minor plot points from the original, but the plot of the story is close to the original.\",\n",
        "        \"1\": \"The story has major plot points added, changed, or removed which changes the story significantly from the original.\",\n",
        "        \"0\": \"The story is completely different from the original.\",\n",
        "    },\n",
        "    input_variables=[\"original\"]\n",
        ")\n",
        "faithfulness = PointwiseMetric(\n",
        "    metric=\"faithfulness\",\n",
        "    metric_prompt_template=faithfulness_quality_template,\n",
        ")\n",
        "\n",
        "print(story_quality.metric_prompt_template)\n"
      ],
      "id": "EGe_vlUvPVOM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also created a third metric type:\n",
        "3.   Lesson quality: evaluate the quality of the lesson at the end of the story. Is it insightful? And does it follow from the details of the story?\n",
        "\n",
        "We used the custom metric quality prompt instead of using the template, as the fields used are `story` and `lesson` which are different from the `prompt` and `response` fields used in the template. In our dataset, the model is asked to produce both a story and a lesson in a json that we have separated out in our dataset."
      ],
      "metadata": {
        "id": "l0oj-2Bkh7uS"
      },
      "id": "l0oj-2Bkh7uS"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "lesson_prompt_template = \"\"\"\n",
        "# Instruction\n",
        "You are an expert evaluator. Your task is to evaluate the quality of the responses generated by AI models. We will provide you with the user prompt and an AI-generated responses.\n",
        "You should first read the user input carefully for analyzing the task, and then evaluate the quality of the responses based on the Criteria provided in the Evaluation section below.\n",
        "You will assign the response a rating following the Rating Rubric and Evaluation Steps. Give step by step explanations for your rating, and only choose ratings from the Rating Rubric.\n",
        "\n",
        "\n",
        "# Evaluation\n",
        "## Criteria\n",
        "applicability: The lesson is drawn directly from details contained in the story.\n",
        "insightfulness: The text contains an actionable, useful life lesson applicable to living a happy and fulfilling life with others and oneself.\n",
        "\n",
        "## Rating Rubric\n",
        "0: The lesson is not insightful and is not applicable to the story.\n",
        "1: The lesson is not insightful, and can only be drawn from minor details in the story.\n",
        "2: The lesson is not insightful, and can be directly drawn from the major plot in to the story.\n",
        "3: The lesson is somewhat insightful, and can be directly drawn from the major plot in the story.\n",
        "4: The lesson is insightful, and can be directly drawn from the major plot in the story.\n",
        "5: The lesson is very insightful and can be directly drawn from the major plot of the story.\n",
        "\n",
        "## Evaluation Steps\n",
        "Step 1: Assess the response in aspects of all criteria provided. Provide assessment according to each criterion.\n",
        "Step 2: Score based on the rating rubric. Give a brief rationale to explain your evaluation considering each individual criterion.\n",
        "\n",
        "\n",
        "# User Inputs and AI-generated Response\n",
        "## User Inputs\n",
        "### story\n",
        "{story}\n",
        "\n",
        "### lesson\n",
        "{lesson}\n",
        "\"\"\"\n",
        "\n",
        "lesson_quality = PointwiseMetric(\n",
        "    metric=\"lesson_quality\",\n",
        "    metric_prompt_template=lesson_prompt_template,\n",
        "\n",
        ")\n",
        "\n",
        "print(lesson_quality.metric_prompt_template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRFsXHQYh60H",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730729931847,
          "user_tz": 300,
          "elapsed": 131,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "acaae68f-49a0-4e62-ad3d-8a989f7fcfb8"
      },
      "id": "pRFsXHQYh60H",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "# Instruction\n",
            "You are an expert evaluator. Your task is to evaluate the quality of the responses generated by AI models. We will provide you with the user prompt and an AI-generated responses.\n",
            "You should first read the user input carefully for analyzing the task, and then evaluate the quality of the responses based on the Criteria provided in the Evaluation section below.\n",
            "You will assign the response a rating following the Rating Rubric and Evaluation Steps. Give step by step explanations for your rating, and only choose ratings from the Rating Rubric.\n",
            "\n",
            "\n",
            "# Evaluation\n",
            "## Criteria\n",
            "applicability: The lesson is drawn directly from details contained in the story.\n",
            "insightfulness: The text contains an actionable, useful life lesson applicable to living a happy and fulfilling life with others and oneself.\n",
            "\n",
            "## Rating Rubric\n",
            "0: The lesson is not insightful and is not applicable to the story.\n",
            "1: The lesson is not insightful, and can only be drawn from minor details in the story.\n",
            "2: The lesson is not insightful, and can be directly drawn from the major plot in to the story.\n",
            "3: The lesson is somewhat insightful, and can be directly drawn from the major plot in the story.\n",
            "4: The lesson is insightful, and can be directly drawn from the major plot in the story.\n",
            "5: The lesson is very insightful and can be directly drawn from the major plot of the story.\n",
            "\n",
            "## Evaluation Steps\n",
            "Step 1: Assess the response in aspects of all criteria provided. Provide assessment according to each criterion.\n",
            "Step 2: Score based on the rating rubric. Give a brief rationale to explain your evaluation considering each individual criterion.\n",
            "\n",
            "\n",
            "# User Inputs and AI-generated Response\n",
            "## User Inputs\n",
            "### story\n",
            "{story}\n",
            "\n",
            "### lesson\n",
            "{lesson}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the dataset into a dataframe.  Our dataset looks like the following:\n",
        "\n",
        "\n",
        "```\n",
        "{\n",
        "  \"instruction\": <prompt instruction>,\n",
        "  \"original\": <original story>,\n",
        "  \"system_instruction\": <system prompt>,\n",
        "  \"story\": <AI generated story based on the original story>,\n",
        "  \"lesson\": <AI generated lesson drawn from the story>,\n",
        "}\n",
        "```\n",
        "\n",
        "We load 25 records it into a pandas dataframe just to reduce the amount of time it takes to run the evaluation.\n"
      ],
      "metadata": {
        "id": "Spjuqa1tasPz"
      },
      "id": "Spjuqa1tasPz"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import storage\n",
        "import json\n",
        "\n",
        "stories_prefix = 'stories'\n",
        "storage_client = storage.Client()\n",
        "bucket = storage_client.bucket(BUCKET)\n",
        "dataset_path = f\"{stories_prefix}/stories_dataset.jsonl\"\n",
        "dataset_blob = bucket.blob(dataset_path)\n",
        "\n",
        "dataset = []\n",
        "\n",
        "with dataset_blob.open(mode='r') as f:\n",
        "  for line in f:\n",
        "    json_line = json.loads(line)\n",
        "    dataset.append(json_line)\n",
        "\n",
        "eval_dataset = pd.DataFrame.from_dict(dataset)"
      ],
      "metadata": {
        "id": "AS6F_LOHz9VJ",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730729839322,
          "user_tz": 300,
          "elapsed": 674,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "AS6F_LOHz9VJ",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is an example output of one of the entries in our dataset:"
      ],
      "metadata": {
        "id": "3DX6L5RkkXOJ"
      },
      "id": "3DX6L5RkkXOJ"
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_colwidth', 2000)\n",
        "display(eval_dataset.loc[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "CQqaoXPrkYPZ",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730729842940,
          "user_tz": 300,
          "elapsed": 107,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "789d564e-ff73-4222-d16e-4767fbffa0f0"
      },
      "id": "CQqaoXPrkYPZ",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "instruction                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \\nMake the story more interesting. Do not add, remove, or change any details from the story.  Only add sentences to elaborate\\non what is already written. **Do not change any of the character's dialog.** Include a lesson at the end that children can\\nlearn from the story.\\n\\nStory:\\n\n",
              "original                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Jack was very enthusiastic. He wanted to do something special. He asked his mom what he could do.\\n\\n\"Why don't you try to prevent something bad from happening,\" his mom said.\\n\\nJack looked at her with confusion.\\n\\n\"What does that mean?\" he asked.\\n\\n\"It means that you can use your shoulder to stop something from happening,\" his mom explained.\\n\\nJack was excited. He put his shoulder against the door to prevent it from opening. His mom was proud of him.\\n\\nJack felt a sense of accomplishment. He was pleased that he could prevent something bad from happening. He was glad that he could help.\\n\n",
              "system_instruction                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \\nYou are a children's story editor. You will be shown a simple children's story that you will be asked to add\\ndetails to the story to make it more engaging for children.\\n\n",
              "story                 Jack was very enthusiastic. He was a young boy with a lot of energy, and he was always looking for new things to do.  He wanted to do something special. He wanted to do something that would make his mom proud and make him feel good about himself. He asked his mom what he could do. He bounced up and down, eager to hear her suggestion.\\n\\n\"Why don't you try to prevent something bad from happening,\" his mom said.  She smiled at her son and placed a hand on his shoulder.\\n\\nJack looked at her with confusion.  His eyebrows furrowed together as he tried to understand what she meant. He tilted his head, his eyes wide.\\n\\n\"What does that mean?\" he asked.  He truly wanted to understand what his mom was saying so he could do what she wanted. \\n\\n\"It means that you can use your shoulder to stop something from happening,\" his mom explained.  She looked around the room to think of an example of how Jack could prevent something from happening.\\n\\nJack was excited.  His face lit up with excitement at the thought of using his shoulder to help. He put his shoulder against the door to prevent it from opening.  He pushed as hard as he could. The door rattled but held firm. His mom was proud of him.  She gave him a big hug and a kiss on the forehead. She knew he truly wanted to be a helper.\\n\\nJack felt a sense of accomplishment. He was pleased that he could prevent something bad from happening.  He imagined all the bad things that could have come in through the door, and he felt strong that he was able to stop it. He was glad that he could help. He looked around the room for more things to prevent.\n",
              "lesson                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             The lesson of this story is that everyone can do something helpful.  Even if it seems small, any effort to make things better can lead to big results.  Just like Jack used his shoulder to help prevent something bad from happening, we can all use our talents and abilities to contribute to a greater good and improve the world around us, one small act at a time.\n",
              "Name: 0, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>instruction</th>\n",
              "      <td>\\nMake the story more interesting. Do not add, remove, or change any details from the story.  Only add sentences to elaborate\\non what is already written. **Do not change any of the character's dialog.** Include a lesson at the end that children can\\nlearn from the story.\\n\\nStory:\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>original</th>\n",
              "      <td>Jack was very enthusiastic. He wanted to do something special. He asked his mom what he could do.\\n\\n\"Why don't you try to prevent something bad from happening,\" his mom said.\\n\\nJack looked at her with confusion.\\n\\n\"What does that mean?\" he asked.\\n\\n\"It means that you can use your shoulder to stop something from happening,\" his mom explained.\\n\\nJack was excited. He put his shoulder against the door to prevent it from opening. His mom was proud of him.\\n\\nJack felt a sense of accomplishment. He was pleased that he could prevent something bad from happening. He was glad that he could help.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>system_instruction</th>\n",
              "      <td>\\nYou are a children's story editor. You will be shown a simple children's story that you will be asked to add\\ndetails to the story to make it more engaging for children.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>story</th>\n",
              "      <td>Jack was very enthusiastic. He was a young boy with a lot of energy, and he was always looking for new things to do.  He wanted to do something special. He wanted to do something that would make his mom proud and make him feel good about himself. He asked his mom what he could do. He bounced up and down, eager to hear her suggestion.\\n\\n\"Why don't you try to prevent something bad from happening,\" his mom said.  She smiled at her son and placed a hand on his shoulder.\\n\\nJack looked at her with confusion.  His eyebrows furrowed together as he tried to understand what she meant. He tilted his head, his eyes wide.\\n\\n\"What does that mean?\" he asked.  He truly wanted to understand what his mom was saying so he could do what she wanted. \\n\\n\"It means that you can use your shoulder to stop something from happening,\" his mom explained.  She looked around the room to think of an example of how Jack could prevent something from happening.\\n\\nJack was excited.  His face lit up with excitement at the thought of using his shoulder to help. He put his shoulder against the door to prevent it from opening.  He pushed as hard as he could. The door rattled but held firm. His mom was proud of him.  She gave him a big hug and a kiss on the forehead. She knew he truly wanted to be a helper.\\n\\nJack felt a sense of accomplishment. He was pleased that he could prevent something bad from happening.  He imagined all the bad things that could have come in through the door, and he felt strong that he was able to stop it. He was glad that he could help. He looked around the room for more things to prevent.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lesson</th>\n",
              "      <td>The lesson of this story is that everyone can do something helpful.  Even if it seems small, any effort to make things better can lead to big results.  Just like Jack used his shoulder to help prevent something bad from happening, we can all use our talents and abilities to contribute to a greater good and improve the world around us, one small act at a time.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's test one of the metrics on one of the examples in our dataset."
      ],
      "metadata": {
        "id": "D4kRBjYs8Bqy"
      },
      "id": "D4kRBjYs8Bqy"
    },
    {
      "cell_type": "code",
      "source": [
        "from vertexai.generative_models import GenerativeModel, GenerationConfig, Part, SafetySetting, FinishReason\n",
        "\n",
        "max_tokens = 8192\n",
        "temperature = 1\n",
        "top_p = 0.95\n",
        "\n",
        "model = GenerativeModel(\n",
        "  \"gemini-1.5-pro-002\",\n",
        ")\n",
        "\n",
        "response = model.generate_content(\n",
        "    contents=[\n",
        "        faithfulness.metric_prompt_template.format(\n",
        "            original=eval_dataset.loc[0]['original'],\n",
        "            response=eval_dataset.loc[0]['story']\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZNBDnu48JIJ",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730737896511,
          "user_tz": 300,
          "elapsed": 3627,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "5934963d-7d4c-4b7b-954a-a167751f9d6b"
      },
      "id": "MZNBDnu48JIJ",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1:\n",
            "Faithfulness: The AI response adds descriptions of Jack's feelings, actions, and his mom's actions. While these additions provide more context and imagery, they don't change the original events or dialogue.  The core storyline remains intact.\n",
            "\n",
            "\n",
            "Step 2:\n",
            "Rating: 4\n",
            "\n",
            "Rationale: The AI-generated story adds details like Jack's enthusiasm being described as \"bouncing up and down,\" his mom placing a hand on his shoulder, and Jack pushing hard against the door. These are minor additions that enhance the descriptions but don't alter the plot or dialogue. Therefore, a rating of 4 is appropriate, as it signifies minor details added while keeping the core story intact.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's evaluate the four metrics `[fluency, story_quality, faithfulness, lesson_quality]`. This effectively the prompts to our LLM model to determine the scores and aggregates them into an Experiment tracked inside of Vertex AI.  \n",
        "\n",
        "If you're running inside of Colab Enterprise, you can see the experiment inline in the notebook interface and evaluate each of the metric scores.\n",
        "\n",
        "Note we mapped `response` to `story` here in the `EvalTask` as discussed above."
      ],
      "metadata": {
        "id": "fEAWFSf3YzOe"
      },
      "id": "fEAWFSf3YzOe"
    },
    {
      "cell_type": "code",
      "source": [
        "eval_task = EvalTask(\n",
        "    dataset=eval_dataset.sample(10),\n",
        "    metric_column_mapping={\n",
        "        \"prompt\": \"instruction\",\n",
        "        \"response\": \"story\",\n",
        "    },\n",
        "    metrics=[\n",
        "        MetricPromptTemplateExamples.Pointwise.FLUENCY,\n",
        "        story_quality,\n",
        "        faithfulness,\n",
        "        lesson_quality\n",
        "    ],\n",
        "    experiment=EXPERIMENT_NAME\n",
        ")\n",
        "\n",
        "eval_result = eval_task.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "eTrky2Ajapv6",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730730015283,
          "user_tz": 300,
          "elapsed": 49383,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "2a5f703e-8ad9-44be-ec03-d9031a101541"
      },
      "id": "eTrky2Ajapv6",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        \n",
              "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
              "    <style>\n",
              "      .view-vertex-resource,\n",
              "      .view-vertex-resource:hover,\n",
              "      .view-vertex-resource:visited {\n",
              "        position: relative;\n",
              "        display: inline-flex;\n",
              "        flex-direction: row;\n",
              "        height: 32px;\n",
              "        padding: 0 12px;\n",
              "          margin: 4px 18px;\n",
              "        gap: 4px;\n",
              "        border-radius: 4px;\n",
              "\n",
              "        align-items: center;\n",
              "        justify-content: center;\n",
              "        background-color: rgb(255, 255, 255);\n",
              "        color: rgb(51, 103, 214);\n",
              "\n",
              "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
              "        font-size: 13px;\n",
              "        font-weight: 500;\n",
              "        text-transform: uppercase;\n",
              "        text-decoration: none !important;\n",
              "\n",
              "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
              "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active {\n",
              "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
              "        position: absolute;\n",
              "        top: 0;\n",
              "        bottom: 0;\n",
              "        left: 0;\n",
              "        right: 0;\n",
              "        border-radius: 4px;\n",
              "        pointer-events: none;\n",
              "\n",
              "        content: '';\n",
              "        background-color: rgb(51, 103, 214);\n",
              "        opacity: 0.12;\n",
              "      }\n",
              "      .view-vertex-icon {\n",
              "        font-size: 18px;\n",
              "      }\n",
              "    </style>\n",
              "  \n",
              "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-0740c353-ba8c-40a9-bcec-946aea187c20\" href=\"#view-view-vertex-resource-0740c353-ba8c-40a9-bcec-946aea187c20\">\n",
              "          <span class=\"material-icons view-vertex-icon\">science</span>\n",
              "          <span>View Experiment</span>\n",
              "        </a>\n",
              "        \n",
              "        <script>\n",
              "          (function () {\n",
              "            const link = document.getElementById('view-vertex-resource-0740c353-ba8c-40a9-bcec-946aea187c20');\n",
              "            link.addEventListener('click', (e) => {\n",
              "              if (window.google?.colab?.openUrl) {\n",
              "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/stories-dataset-experiment/runs?project=jkwng-vertex-playground');\n",
              "              } else {\n",
              "                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/stories-dataset-experiment/runs?project=jkwng-vertex-playground', '_blank');\n",
              "              }\n",
              "              e.stopPropagation();\n",
              "              e.preventDefault();\n",
              "            });\n",
              "          })();\n",
              "        </script>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.metadata.experiment_resources:Associating projects/205512073711/locations/us-central1/metadataStores/default/contexts/stories-dataset-experiment-60ced10d-35d3-4531-82ca-a8c736def105 to Experiment: stories-dataset-experiment\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        \n",
              "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
              "    <style>\n",
              "      .view-vertex-resource,\n",
              "      .view-vertex-resource:hover,\n",
              "      .view-vertex-resource:visited {\n",
              "        position: relative;\n",
              "        display: inline-flex;\n",
              "        flex-direction: row;\n",
              "        height: 32px;\n",
              "        padding: 0 12px;\n",
              "          margin: 4px 18px;\n",
              "        gap: 4px;\n",
              "        border-radius: 4px;\n",
              "\n",
              "        align-items: center;\n",
              "        justify-content: center;\n",
              "        background-color: rgb(255, 255, 255);\n",
              "        color: rgb(51, 103, 214);\n",
              "\n",
              "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
              "        font-size: 13px;\n",
              "        font-weight: 500;\n",
              "        text-transform: uppercase;\n",
              "        text-decoration: none !important;\n",
              "\n",
              "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
              "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active {\n",
              "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
              "        position: absolute;\n",
              "        top: 0;\n",
              "        bottom: 0;\n",
              "        left: 0;\n",
              "        right: 0;\n",
              "        border-radius: 4px;\n",
              "        pointer-events: none;\n",
              "\n",
              "        content: '';\n",
              "        background-color: rgb(51, 103, 214);\n",
              "        opacity: 0.12;\n",
              "      }\n",
              "      .view-vertex-icon {\n",
              "        font-size: 18px;\n",
              "      }\n",
              "    </style>\n",
              "  \n",
              "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-9979e056-32ed-492d-b2e7-a1a395038d0e\" href=\"#view-view-vertex-resource-9979e056-32ed-492d-b2e7-a1a395038d0e\">\n",
              "          <span class=\"material-icons view-vertex-icon\">science</span>\n",
              "          <span>View Experiment Run</span>\n",
              "        </a>\n",
              "        \n",
              "        <script>\n",
              "          (function () {\n",
              "            const link = document.getElementById('view-vertex-resource-9979e056-32ed-492d-b2e7-a1a395038d0e');\n",
              "            link.addEventListener('click', (e) => {\n",
              "              if (window.google?.colab?.openUrl) {\n",
              "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/stories-dataset-experiment/runs/stories-dataset-experiment-60ced10d-35d3-4531-82ca-a8c736def105?project=jkwng-vertex-playground');\n",
              "              } else {\n",
              "                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/stories-dataset-experiment/runs/stories-dataset-experiment-60ced10d-35d3-4531-82ca-a8c736def105?project=jkwng-vertex-playground', '_blank');\n",
              "              }\n",
              "              e.stopPropagation();\n",
              "              e.preventDefault();\n",
              "            });\n",
              "          })();\n",
              "        </script>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:vertexai.evaluation._evaluation:Computing metrics with a total of 40 Vertex Gen AI Evaluation Service API requests.\n",
            "100%|██████████| 40/40 [00:48<00:00,  1.21s/it]\n",
            "WARNING:vertexai.evaluation._evaluation:2 errors encountered during evaluation. Continue to compute summary metrics for the rest of the dataset.\n",
            "WARNING:vertexai.evaluation._evaluation:Error encountered for metric story_quality at dataset index 592: Error: 500 Failed to make GenerateContent request to judge model. If you're using a new project, expect a delay and retry in a few minutes.\n",
            "WARNING:vertexai.evaluation._evaluation:Error encountered for metric faithfulness at dataset index 935: Error: 500 Failed to make GenerateContent request to judge model. If you're using a new project, expect a delay and retry in a few minutes.\n",
            "INFO:vertexai.evaluation._evaluation:Evaluation Took:48.37069001699996 seconds\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        \n",
              "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
              "    <style>\n",
              "      .view-vertex-resource,\n",
              "      .view-vertex-resource:hover,\n",
              "      .view-vertex-resource:visited {\n",
              "        position: relative;\n",
              "        display: inline-flex;\n",
              "        flex-direction: row;\n",
              "        height: 32px;\n",
              "        padding: 0 12px;\n",
              "          margin: 4px 18px;\n",
              "        gap: 4px;\n",
              "        border-radius: 4px;\n",
              "\n",
              "        align-items: center;\n",
              "        justify-content: center;\n",
              "        background-color: rgb(255, 255, 255);\n",
              "        color: rgb(51, 103, 214);\n",
              "\n",
              "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
              "        font-size: 13px;\n",
              "        font-weight: 500;\n",
              "        text-transform: uppercase;\n",
              "        text-decoration: none !important;\n",
              "\n",
              "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
              "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active {\n",
              "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
              "        position: absolute;\n",
              "        top: 0;\n",
              "        bottom: 0;\n",
              "        left: 0;\n",
              "        right: 0;\n",
              "        border-radius: 4px;\n",
              "        pointer-events: none;\n",
              "\n",
              "        content: '';\n",
              "        background-color: rgb(51, 103, 214);\n",
              "        opacity: 0.12;\n",
              "      }\n",
              "      .view-vertex-icon {\n",
              "        font-size: 18px;\n",
              "      }\n",
              "    </style>\n",
              "  \n",
              "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-d5294392-e02a-4be3-8ec0-e0c3380693f1\" href=\"#view-view-vertex-resource-d5294392-e02a-4be3-8ec0-e0c3380693f1\">\n",
              "          <span class=\"material-icons view-vertex-icon\">science</span>\n",
              "          <span>View Experiment</span>\n",
              "        </a>\n",
              "        \n",
              "        <script>\n",
              "          (function () {\n",
              "            const link = document.getElementById('view-vertex-resource-d5294392-e02a-4be3-8ec0-e0c3380693f1');\n",
              "            link.addEventListener('click', (e) => {\n",
              "              if (window.google?.colab?.openUrl) {\n",
              "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/stories-dataset-experiment/runs?project=jkwng-vertex-playground');\n",
              "              } else {\n",
              "                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/stories-dataset-experiment/runs?project=jkwng-vertex-playground', '_blank');\n",
              "              }\n",
              "              e.stopPropagation();\n",
              "              e.preventDefault();\n",
              "            });\n",
              "          })();\n",
              "        </script>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "stories_evaluation.ipynb"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}